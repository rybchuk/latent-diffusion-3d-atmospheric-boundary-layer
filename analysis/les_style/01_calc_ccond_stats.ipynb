{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and sort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identify sample files\n",
    "ckl_in = Path('/projects/wakedynamics/orybchuk/ldm-3d/logs/2022-12-01T22-01-37_inpaint_geo_raaw_kl1/images/test/postprocessed')\n",
    "ckl_files = list(Path(ckl_in).glob('*.npy'))\n",
    "ckl_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare four large sample arrays\n",
    "# ncbatch = min(len(ccont_files), len(ucontp_files), len(ukl_files), len(uklp_files))\n",
    "ncbatch = len(ckl_files)\n",
    "tmp_samp = np.load(ckl_files[0])\n",
    "ccond_shape = [ncbatch]+list(tmp_samp.shape)\n",
    "    \n",
    "tmp_kl = np.zeros(ccond_shape)\n",
    "for i in range(ncbatch):\n",
    "    tmp_kl[i,:,:,:,:] = np.load(ckl_files[i]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert to Dataset\n",
    "## Prepare metadata\n",
    "xdim = np.arange(0, 1920, 15)\n",
    "ydim = np.arange(0, 1920, 15)\n",
    "zdim = np.arange(0, 480, 15)  # Chop vertical dim in half to avoid looking above capping inversion\n",
    "coords = dict(x=xdim, y=ydim, z=zdim)\n",
    "\n",
    "def unnorm(xp, xmin, xmax):\n",
    "    '''\n",
    "    Take data from [-1,1] back to the original values\n",
    "    '''\n",
    "    return (xp + 1)*0.5*(xmax-xmin)+xmin\n",
    "\n",
    "umin, umax, vmin, vmax, wmin, wmax = 2.86975098, 12.5567627, -0.9810791, 4.91235352, -1.98095703, 2.5579834\n",
    "\n",
    "## Create Dataset\n",
    "ds_c = xr.Dataset(coords=coords)\n",
    "\n",
    "ds_c['u_kl'] = (('sample', 'x', 'y', 'z'), unnorm(tmp_kl[:,0,:,:,:32], umin, umax))\n",
    "ds_c['v_kl'] = (('sample', 'x', 'y', 'z'), unnorm(tmp_kl[:,1,:,:,:32], vmin, vmax))\n",
    "ds_c['w_kl'] = (('sample', 'x', 'y', 'z'), unnorm(tmp_kl[:,2,:,:,:32], wmin, wmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocity profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate stats\n",
    "for vel in ['u', 'v', 'w']:\n",
    "    ds_c[vel+'_kl'].mean(('sample', 'x', 'y')).to_netcdf(vel+'_ccond_kl_raaw_mean.nc')\n",
    "    ds_c[vel+'_kl'].std(('sample', 'x', 'y')).to_netcdf(vel+'_ccond_kl_raaw_std.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate profiles of kinematic flux\n",
    "## Calculate fluctuations\n",
    "ds_c[\"up_kl\"] = ds_c['u_kl'] - ds_c['u_kl'].mean(('x', 'y'))\n",
    "ds_c[\"vp_kl\"] = ds_c['v_kl'] - ds_c['v_kl'].mean(('x', 'y'))\n",
    "ds_c[\"wp_kl\"] = ds_c['w_kl'] - ds_c['w_kl'].mean(('x', 'y'))\n",
    "\n",
    "## Calculate fluxes\n",
    "ds_c[\"upvp_kl\"] = (ds_c['up_kl'] * ds_c['vp_kl']).mean(('x', 'y'))\n",
    "\n",
    "ds_c[\"upwp_kl\"] = (ds_c['up_kl'] * ds_c['wp_kl']).mean(('x', 'y'))\n",
    "\n",
    "ds_c[\"vpwp_kl\"] = (ds_c['vp_kl'] * ds_c['wp_kl']).mean(('x', 'y'))\n",
    "\n",
    "# Save\n",
    "ds_c[\"upvp_kl\"].mean('sample').to_netcdf(\"upvp_ccond_kl_raaw.nc\")\n",
    "ds_c[\"upwp_kl\"].mean('sample').to_netcdf(\"upwp_ccond_kl_raaw.nc\")\n",
    "ds_c[\"vpwp_kl\"].mean('sample').to_netcdf(\"vpwp_ccond_kl_raaw.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocity PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate histograms and PDFs\n",
    "## Bins\n",
    "umin = 6\n",
    "umax = 12\n",
    "ubins = np.linspace(umin, umax, 500)\n",
    "\n",
    "vmin = -1.5\n",
    "vmax = 3.5\n",
    "vbins = np.linspace(vmin, vmax, 500)\n",
    "\n",
    "wmin = -0.75\n",
    "wmax = 0.75\n",
    "wbins = np.linspace(wmin, wmax, 300)\n",
    "\n",
    "## Scipy histograms\n",
    "uhist_np_kl = np.histogram(ds_c['u_kl'].values.flatten(), bins=ubins)\n",
    "uhist_kl = scipy.stats.rv_histogram(uhist_np_kl)\n",
    "\n",
    "vhist_np_kl = np.histogram(ds_c['v_kl'].values.flatten(), bins=vbins)\n",
    "vhist_kl = scipy.stats.rv_histogram(vhist_np_kl)\n",
    "\n",
    "whist_np_kl = np.histogram(ds_c['w_kl'].values.flatten(), bins=wbins)\n",
    "whist_kl = scipy.stats.rv_histogram(whist_np_kl)\n",
    "\n",
    "## Save\n",
    "np.save('u_ccond_kl_raaw_hist.npy', uhist_kl.pdf(ubins))\n",
    "np.save('v_ccond_kl_raaw_hist.npy', vhist_kl.pdf(vbins))\n",
    "np.save('w_ccond_kl_raaw_hist.npy', whist_kl.pdf(wbins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate 1D spectra, sample by sample\n",
    "khub = 6\n",
    "tmp1 = ds_c['up_kl'].isel(sample=0, z=khub)\n",
    "tmp2 = np.fft.rfftn(tmp1.values, axes=(0,))\n",
    "all_spectra_kl = np.zeros((len(ds_c['sample']), len(tmp2)))    \n",
    "all_spectra_klp = np.zeros((len(ds_c['sample']), len(tmp2)))    \n",
    "    \n",
    "for i in range(len(ds_c['sample'])):\n",
    "    up_xy_test = ds_c['up_kl'].isel(sample=i, z=khub)\n",
    "    up_k_test = np.fft.rfftn(up_xy_test.values, axes=(0,))\n",
    "    up_k_bar_test = np.mean(np.abs(up_k_test)**2, axis=1)\n",
    "    all_spectra_kl[i,:] = up_k_bar_test.copy()\n",
    "    \n",
    "np.save('spectra_ccond_kl_raaw.npy', all_spectra_kl.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate pdf's of gradients + divergence\n",
    "## Parameters\n",
    "dx, dy, dz = 15, 15, 15\n",
    "facx, facy, facz = 1/(4*dx), 1/(4*dy), 1/(4*dz)\n",
    "dmin = -0.02\n",
    "dmax = 0.02\n",
    "dbins = np.linspace(dmin, dmax, 500)\n",
    "\n",
    "## Set up history arrays\n",
    "all_dudx_hist_kl = np.zeros((len(ds_c['sample']), len(dbins)))\n",
    "all_dvdy_hist_kl = np.zeros((len(ds_c['sample']), len(dbins)))\n",
    "all_dwdz_hist_kl = np.zeros((len(ds_c['sample']), len(dbins)))\n",
    "all_div_hist_kl = np.zeros((len(ds_c['sample']), len(dbins)))\n",
    "\n",
    "## Calculate pdf's\n",
    "for i in range(len(ds_c['sample'])):\n",
    "    vel = ds_c.isel(sample=i)\n",
    "    \n",
    "    # Calculate gradients + divergence\n",
    "    dudx_kl = facx*(-vel['u_kl'].roll(x=-1,y=-1,z=-1).values + vel['u_kl'].roll(x=0,y=-1,z=-1).values \\\n",
    "                    -vel['u_kl'].roll(x=-1,y=0 ,z=-1).values + vel['u_kl'].roll(x=0,y=0 ,z=-1).values \\\n",
    "                    -vel['u_kl'].roll(x=-1,y=-1,z=0 ).values + vel['u_kl'].roll(x=0,y=-1,z=0 ).values \\\n",
    "                    -vel['u_kl'].roll(x=-1,y=0 ,z=0 ).values + vel['u_kl'].roll(x=0,y=0 ,z=0 ).values)\n",
    "    dvdy_kl = facy*(-vel['v_kl'].roll(x=-1,y=-1,z=-1).values - vel['v_kl'].roll(x=0,y=-1,z=-1).values \\\n",
    "                    +vel['v_kl'].roll(x=-1,y=0 ,z=-1).values + vel['v_kl'].roll(x=0,y=0 ,z=-1).values \\\n",
    "                    -vel['v_kl'].roll(x=-1,y=-1,z=0 ).values - vel['v_kl'].roll(x=0,y=-1,z=0 ).values \\\n",
    "                    +vel['v_kl'].roll(x=-1,y=0 ,z=0 ).values + vel['v_kl'].roll(x=0,y=0 ,z=0 ).values)\n",
    "    dwdz_kl = facz*(-vel['w_kl'].roll(x=-1,y=-1,z=-1).values - vel['w_kl'].roll(x=0,y=-1,z=-1).values \\\n",
    "                    -vel['w_kl'].roll(x=-1,y=0 ,z=-1).values - vel['w_kl'].roll(x=0,y=0 ,z=-1).values \\\n",
    "                    +vel['w_kl'].roll(x=-1,y=-1,z=0 ).values + vel['w_kl'].roll(x=0,y=-1,z=0 ).values \\\n",
    "                    +vel['w_kl'].roll(x=-1,y=0 ,z=0 ).values + vel['w_kl'].roll(x=0,y=0 ,z=0 ).values)\n",
    "    div_kl = dudx_kl + dvdy_kl + dwdz_kl\n",
    "    \n",
    "    # Calculate histograms\n",
    "    duhist_kl_np = np.histogram(dudx_kl.flatten(), bins=dbins)\n",
    "    duhist_kl = scipy.stats.rv_histogram(duhist_kl_np)  \n",
    "    dvhist_kl_np = np.histogram(dvdy_kl.flatten(), bins=dbins)\n",
    "    dvhist_kl = scipy.stats.rv_histogram(dvhist_kl_np)  \n",
    "    dwhist_kl_np = np.histogram(dwdz_kl.flatten(), bins=dbins)\n",
    "    dwhist_kl = scipy.stats.rv_histogram(dwhist_kl_np) \n",
    "    ddivhist_kl_np = np.histogram(div_kl.flatten(), bins=dbins)\n",
    "    ddivhist_kl = scipy.stats.rv_histogram(ddivhist_kl_np) \n",
    "    \n",
    "    # Store\n",
    "    all_dudx_hist_kl[i,:] = duhist_kl.pdf(dbins)\n",
    "    all_dvdy_hist_kl[i,:] = dvhist_kl.pdf(dbins)\n",
    "    all_dwdz_hist_kl[i,:] = dwhist_kl.pdf(dbins)\n",
    "    all_div_hist_kl[i,:] = ddivhist_kl.pdf(dbins)\n",
    "    \n",
    "np.save('dudx_ccond_kl_raaw_hist.npy', all_dudx_hist_kl.mean(axis=0))\n",
    "np.save('dvdy_ccond_kl_raaw_hist.npy', all_dvdy_hist_kl.mean(axis=0))\n",
    "np.save('dwdz_ccond_kl_raaw_hist.npy', all_dwdz_hist_kl.mean(axis=0))\n",
    "np.save('div_ccond_kl_raaw_hist.npy', all_div_hist_kl.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daskenv202305",
   "language": "python",
   "name": "daskenv202305"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
