{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a directory containing 1D HDF5 output from AMR-Wind to 3D `.npy` files. Terminology: `big_box` refers to the entire domain. `little_box` refers to the smaller chunks of data, each of which is presumably output by a single process in the AMR-Wind writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import hdf5plugin\n",
    "from matplotlib.colors import TwoSlopeNorm, BoundaryNorm, LinearSegmentedColormap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### User inputs\n",
    "desired_channels = ['velocityx', 'velocityy', 'velocityz']\n",
    "input_dir = Path('/scratch/orybchuk/wakedynamics/ldm-3d/simulations/train')\n",
    "output_dir = Path('/scratch/orybchuk/wakedynamics/ldm-3d/simulations/train/npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identify HDF5 files\n",
    "h5_files = list(Path(input_dir).glob('*.h5'))\n",
    "h5_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5041\n",
      "[PosixPath('/scratch/orybchuk/wakedynamics/ldm-3d/simulations/train/plt100080.h5'), PosixPath('/scratch/orybchuk/wakedynamics/ldm-3d/simulations/train/plt100200.h5'), PosixPath('/scratch/orybchuk/wakedynamics/ldm-3d/simulations/train/plt100320.h5'), PosixPath('/scratch/orybchuk/wakedynamics/ldm-3d/simulations/train/plt100440.h5'), PosixPath('/scratch/orybchuk/wakedynamics/ldm-3d/simulations/train/plt100560.h5')]\n",
      "[PosixPath('/scratch/orybchuk/wakedynamics/ldm-3d/simulations/train/plt99480.h5'), PosixPath('/scratch/orybchuk/wakedynamics/ldm-3d/simulations/train/plt99600.h5'), PosixPath('/scratch/orybchuk/wakedynamics/ldm-3d/simulations/train/plt99720.h5'), PosixPath('/scratch/orybchuk/wakedynamics/ldm-3d/simulations/train/plt99840.h5'), PosixPath('/scratch/orybchuk/wakedynamics/ldm-3d/simulations/train/plt99960.h5')]\n"
     ]
    }
   ],
   "source": [
    "print(len(h5_files))\n",
    "print(h5_files[:5])\n",
    "print(h5_files[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component_0 ,  b'density'\n",
      "component_1 ,  b'gpx'\n",
      "component_10 ,  b'velocity_mueff'\n",
      "component_2 ,  b'gpy'\n",
      "component_3 ,  b'gpz'\n",
      "component_4 ,  b'mu_turb'\n",
      "component_5 ,  b'p'\n",
      "component_6 ,  b'temperature'\n",
      "component_7 ,  b'velocityx'\n",
      "component_8 ,  b'velocityy'\n",
      "component_9 ,  b'velocityz'\n",
      "coordinate_system ,  [0]\n",
      "dim ,  [3]\n",
      "finest_level ,  [0]\n",
      "num_components ,  [11]\n",
      "num_levels ,  [1]\n",
      "plotfile_type ,  b'VanillaHDF5'\n",
      "time ,  [50040.]\n",
      "version_name ,  b'HyperCLaw-V1.1'\n",
      "\n",
      "nvars_tot: 11\n",
      "component_nums_out: {'velocityx': 7, 'velocityy': 8, 'velocityz': 9}\n",
      "(little_di, little_dj, little_dk): (16, 16, 16)\n",
      "(big_nx, big_ny, big_nz): (128, 128, 64)\n"
     ]
    }
   ],
   "source": [
    "### Extract some parameters based on the first data file\n",
    "with h5py.File(h5_files[0], mode='r') as f_ex:\n",
    "    ## ~~~~~~~~~~ File structure ~~~~~~~~~~\n",
    "    ## Count total number of variables in HDF5 file & identify desired channel numbers\n",
    "    nvars_out = len(desired_channels)\n",
    "    nvars_tot = 0\n",
    "    component_nums_out = {}\n",
    "    for key in f_ex.attrs.keys():\n",
    "        print(key, ', ', f_ex.attrs[key])\n",
    "\n",
    "        # Count the total number of variables in the HDF5 file\n",
    "        if 'component_' in key: nvars_tot+=1\n",
    "\n",
    "        if type(f_ex.attrs[key]) == np.bytes_:\n",
    "            # Identify the component number of desired variables\n",
    "            keyval = f_ex.attrs[key].decode('UTF-8')\n",
    "            if keyval in desired_channels:\n",
    "                component_num = int(key.split(\"_\")[1])\n",
    "                component_nums_out[keyval] = component_num\n",
    "\n",
    "        # Identify time\n",
    "        if key == 'time':\n",
    "            filetime = f_ex.attrs[key][0]\n",
    "            assert (filetime).is_integer(), \"Filetime is not an integer! Write additional pre-processing code.\"\n",
    "            filetime = int(filetime)\n",
    "        \n",
    "    print(\"\\nnvars_tot:\", nvars_tot)\n",
    "    print(\"component_nums_out:\", component_nums_out)\n",
    "    \n",
    "    ## ~~~~~~~~~~ Geometry ~~~~~~~~~~\n",
    "    ## Characterize little boxes\n",
    "    little_shape0 = f_ex['level_0']['boxes'][0]\n",
    "    little_di = little_shape0[3] - little_shape0[0] + 1\n",
    "    little_dj = little_shape0[4] - little_shape0[1] + 1\n",
    "    little_dk = little_shape0[5] - little_shape0[2] + 1\n",
    "    little_var_len = little_di*little_dj*little_dk\n",
    "    boxstride = little_var_len*nvars_tot\n",
    "    nlittle = len(f_ex['level_0']['boxes'])\n",
    "\n",
    "    # Check that di/dj/dk are true for all shapes\n",
    "    for box in f_ex['level_0']['boxes']:\n",
    "        assert box[0] + little_di - 1 == box[3], box\n",
    "        assert box[1] + little_dj - 1 == box[4], box\n",
    "        assert box[2] + little_dk - 1 == box[5], box\n",
    "\n",
    "    ## Characterize big box\n",
    "    big_nx = f_ex['level_0'].attrs['prob_domain'][3] + 1\n",
    "    big_ny = f_ex['level_0'].attrs['prob_domain'][4] + 1\n",
    "    big_nz = f_ex['level_0'].attrs['prob_domain'][5] + 1\n",
    "\n",
    "    print(\"(little_di, little_dj, little_dk):\", (little_di, little_dk, little_dk))\n",
    "    print(\"(big_nx, big_ny, big_nz):\", (big_nx, big_ny, big_nz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Extract key data file parameters\n",
    "# ## Characterize little boxes\n",
    "# little_shape0 = f3d['level_0']['boxes'][0]\n",
    "# little_di = little_shape0[3] - little_shape0[0] + 1\n",
    "# little_dj = little_shape0[4] - little_shape0[1] + 1\n",
    "# little_dk = little_shape0[5] - little_shape0[2] + 1\n",
    "# little_var_len = little_di*little_dj*little_dk\n",
    "# boxstride = little_var_len*nvars_tot\n",
    "# nlittle = len(f3d['level_0']['boxes'])\n",
    "\n",
    "# # Check that di/dj/dk are true for all shapes\n",
    "# for box in f3d['level_0']['boxes']:\n",
    "#     assert box[0] + little_di - 1 == box[3], box\n",
    "#     assert box[1] + little_di - 1 == box[4], box\n",
    "#     assert box[2] + little_di - 1 == box[5], box\n",
    "    \n",
    "# ## Characterize big box\n",
    "# big_nx = f3d['level_0'].attrs['prob_domain'][3] + 1\n",
    "# big_ny = f3d['level_0'].attrs['prob_domain'][4] + 1\n",
    "# big_nz = f3d['level_0'].attrs['prob_domain'][5] + 1\n",
    "\n",
    "# print(\"(little_di, little_dj, little_dk):\", (little_di, little_dk, little_dk))\n",
    "# print(\"(big_nx, big_ny, big_nz):\", (big_nx, big_ny, big_nz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare to convert the files\n",
    "var_maxes = np.zeros(nvars_out)\n",
    "var_mins = np.zeros(nvars_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Operate on stats files before starting the main conversion\n",
    "## Purge stats files if they exist\n",
    "fsample_stats = \"sample_stats.csv\"\n",
    "fall_stats = \"all_stats.txt\"\n",
    "\n",
    "if Path(output_dir, fsample_stats).is_file():\n",
    "    Path(output_dir, fsample_stats).unlink()\n",
    "    print(f\"Purged pre-existing {fsample_stats}!\")\n",
    "if Path(output_dir, fall_stats).is_file():\n",
    "    Path(output_dir, fall_stats).unlink()\n",
    "    print(f\"Purged pre-existing {fall_stats}!\")\n",
    "    \n",
    "## Create a header\n",
    "with open(Path(output_dir, fsample_stats), 'w') as fstats:\n",
    "    fstats.write(\"sample, umax, umin, vmax, vmin, wmax, wmin\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "### Iterate over files and convert HDF5 to .npy\n",
    "fnum = 0\n",
    "for fname in h5_files:\n",
    "    if fnum % 100 == 0: print(fnum)\n",
    "    ### ~~~~~ Read the .h5 file ~~~~~\n",
    "    f = h5py.File(fname, mode='r')\n",
    "    \n",
    "    ### ~~~~~ Check that nothing about the geometry changed w.r.t. the reference file ~~~~~\n",
    "    # Check little boxes\n",
    "    for box in f['level_0']['boxes']:\n",
    "        assert box[0] + little_di - 1 == box[3], box\n",
    "        assert box[1] + little_dj - 1 == box[4], box\n",
    "        assert box[2] + little_dk - 1 == box[5], box\n",
    "        \n",
    "    # Check big box\n",
    "    assert f['level_0'].attrs['prob_domain'][3] + 1 == big_nx, \"x-dimension error!\"\n",
    "    assert f['level_0'].attrs['prob_domain'][4] + 1 == big_ny, \"y-dimension error!\"\n",
    "    assert f['level_0'].attrs['prob_domain'][5] + 1 == big_nz, \"z-dimension error!\"\n",
    "    \n",
    "    ### ~~~~~ Reformat 1D into 3D variables ~~~~~\n",
    "    ## Prepare the volume array\n",
    "    big_out = np.zeros((nvars_out, big_nx, big_ny, big_nz))\n",
    "\n",
    "    ## Reformat 1D into 3D data, iterating over variables\n",
    "    for i, var in enumerate(list(component_nums_out.values())):  # Iterate over variables\n",
    "        var_offset = var*little_var_len\n",
    "\n",
    "        for lb in range(nlittle):  # Iterate over little boxes\n",
    "            # Get index of little box\n",
    "            little_inds = f['level_0']['boxes'][lb]\n",
    "            lo_i, lo_j, lo_k = little_inds[0], little_inds[1], little_inds[2]\n",
    "            hi_i, hi_j, hi_k = little_inds[3]+1, little_inds[4]+1, little_inds[5]+1\n",
    "\n",
    "            # Get 1D data\n",
    "            data1d = f['level_0']['data:datatype=0'][var_offset+lb*boxstride:\n",
    "                                                          var_offset+lb*boxstride+little_var_len]\n",
    "\n",
    "            # Reshape into 3D\n",
    "            data3d = np.reshape(data1d,\n",
    "                                (hi_i-lo_i,hi_j-lo_j,hi_k-lo_k),\n",
    "                                order='F')\n",
    "\n",
    "            # Place little 3D data into the big domain\n",
    "            big_out[i,lo_i:hi_i,lo_j:hi_j,lo_k:hi_k] = data3d\n",
    "            \n",
    "    ### ~~~~~ Close .h5 file ~~~~~\n",
    "    f.close()\n",
    "    \n",
    "    ### ~~~~~ Save .npy file ~~~~~\n",
    "    savenum = fname.stem[3:]\n",
    "    savename = 'gt' + savenum + '.npy'\n",
    "    np.save(Path(output_dir, savename), big_out)\n",
    "    \n",
    "    ### ~~~~~ Update statistics ~~~~~\n",
    "    ## Write min/max of each field for each sample to a file\n",
    "    with open(Path(output_dir, fsample_stats), 'a') as fstats:\n",
    "        fstats.write(f\"{savenum}, \")  # Sample ID\n",
    "        for j in range(nvars_out):\n",
    "            fstats.write(f\"{big_out[j,:,:,:].max()}, {big_out[j,:,:,:].min()}, \")\n",
    "        fstats.write(\"\\n\")\n",
    "        \n",
    "    ## Update samplewide min/max\n",
    "    if fnum == 0:\n",
    "        for j in range(nvars_out):\n",
    "            var_maxes[j] = big_out[j,:,:,:].max()\n",
    "            var_mins[j] = big_out[j,:,:,:].min()\n",
    "    else:\n",
    "        for j in range(nvars_out):\n",
    "            var_maxes[j] = max(var_maxes[j], big_out[j,:,:,:].max())\n",
    "            var_mins[j] = min(var_mins[j], big_out[j,:,:,:].min())\n",
    "            \n",
    "    fnum+=1\n",
    "            \n",
    "## Save sample-set statistics\n",
    "with open(Path(output_dir, fall_stats), 'w') as fstats:\n",
    "    for i in range(nvars_out):\n",
    "        fstats.write(f\"Variable number {i} max: {var_maxes[i]}\\n\")\n",
    "        fstats.write(f\"Variable number {i} min: {var_mins[i]}\\n\")\n",
    "    \n",
    "print(\"Variable maximums:\", var_maxes)\n",
    "print(\"Variable minimums:\", var_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do a quick check for obvious outliers or reshaping artifacts\n",
    "fig, ax = plt.subplots(1, 3, figsize=(9,3), dpi=125)\n",
    "\n",
    "for axs in ax.reshape(-1):\n",
    "    axs.set_box_aspect(1)\n",
    "\n",
    "myind = 1\n",
    "\n",
    "for i, var in enumerate(component_nums_out):  # Iterate over variables\n",
    "#     # Top-down view\n",
    "#     im1 = ax[i].imshow(big_out[i,:,:,myind].T)\n",
    "    \n",
    "    # Side view\n",
    "    im1 = ax[i].imshow(big_out[i,:,myind,:].T,\n",
    "                      origin='lower')\n",
    "\n",
    "\n",
    "    ax[i].set_title(desired_channels[i])\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amrex",
   "language": "python",
   "name": "amrex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
